{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import tensorflow as tf\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headers():\n",
    "    return random.choice([\n",
    "        {\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.122 Safari/537.36\"},\n",
    "        {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'},\n",
    "        {'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36'}\n",
    "    ])\n",
    "\n",
    "# Stock class for stock data\n",
    "class Stock:\n",
    "    def __init__(self, ticker, sector):\n",
    "        self.ticker = ticker\n",
    "        self.sector = sector\n",
    "        self.price = 0.0\n",
    "        self.priceurl = f'https://finance.yahoo.com/quote/{self.ticker}'\n",
    "        self.pricehistory = pd.DataFrame()\n",
    "        self.data = {}\n",
    "        self.dataurl = f\"https://finance.yahoo.com/quote/{self.ticker}/key-statistics?p={self.ticker}\"\n",
    "        \n",
    "        # Deep Learning Attributes\n",
    "        self.technical_indicators = pd.DataFrame()\n",
    "        self.today_technical_indicators = pd.DataFrame()\n",
    "        self.labels = pd.DataFrame()\n",
    "        self.prediction = 0.0\n",
    "        \n",
    "        # Metrics\n",
    "        self.metrics = {}\n",
    "        self.metric_aliases = {\n",
    "            'Market Cap (intraday)': 'market_cap',\n",
    "            'Beta (5Y Monthly)': 'beta',\n",
    "            '52 Week High 3': '52_week_high',\n",
    "            '52 Week Low 3': '52_week_low',\n",
    "            '50-Day Moving Average 3': '50_day_ma',\n",
    "            '200-Day Moving Average 3': '200_day_ma',\n",
    "            'Avg Vol (3 month) 3': 'avg_vol_3m',\n",
    "            'Avg Vol (10 day) 3': 'avg_vol_10d',\n",
    "            'Shares Outstanding 5': 'shares_outstanding',\n",
    "            'Float 8': 'float',\n",
    "            '% Held by Insiders 1': 'held_by_insiders',\n",
    "            '% Held by Institutions 1': 'held_by_institutions',\n",
    "            'Short Ratio (Jan 30, 2023) 4': 'short_ratio',\n",
    "            'Payout Ratio 4': 'payout_ratio',\n",
    "            'Profit Margin': 'profit_margin',\n",
    "            'Operating Margin (ttm)': 'operating_margin',\n",
    "            'Return on Assets (ttm)': 'return_on_assets',\n",
    "            'Return on Equity (ttm)': 'return_on_equity',\n",
    "            'Revenue (ttm)': 'revenue',\n",
    "            'Revenue Per Share (ttm)': 'revenue_per_share',\n",
    "            'Gross Profit (ttm)': 'gross_profit',\n",
    "            'EBITDA ': 'ebitda',\n",
    "            'Net Income Avi to Common (ttm)': 'net_income',\n",
    "            'Diluted EPS (ttm)': 'eps',\n",
    "            'Total Cash (mrq)': 'total_cash',\n",
    "            'Total Cash Per Share (mrq)': 'cash_per_share',\n",
    "            'Total Debt (mrq)': 'total_debt',\n",
    "            'Total Debt/Equity (mrq)': 'debt_to_equity',\n",
    "            'Current Ratio (mrq)': 'current_ratio',\n",
    "            'Book Value Per Share (mrq)': 'book_value_per_share',\n",
    "            'Operating Cash Flow (ttm)': 'operating_cash_flow',\n",
    "            'Levered Free Cash Flow (ttm)': 'levered_free_cash_flow'\n",
    "        }\n",
    "        \n",
    "    def scrape_data(self):\n",
    "        #get fundamental info of the firm, saved in stock.data as dictionary\n",
    "        #yf.Ticker(self.ticker).info.keys()\n",
    "        page = requests.get(self.dataurl, headers = get_headers())\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        data = {}\n",
    "        sections = soup.find_all('section', {'data-test': 'qsp-statistics'})\n",
    "        for section in sections:\n",
    "            rows = section.find_all('tr')\n",
    "            for row in rows:\n",
    "                cols = row.find_all('td')\n",
    "                if len(cols) == 2:\n",
    "                    metric = cols[0].text.strip()\n",
    "                    if metric in self.metric_aliases:\n",
    "                        data[self.metric_aliases[metric]] = cols[1].text.strip()\n",
    "\n",
    "        self.data = data\n",
    "    \n",
    "    def get_stock_price(self):\n",
    "        # grab latest price/close price\n",
    "        try:\n",
    "            response = requests.get(self.priceurl, headers = get_headers())\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            data = soup.find('fin-streamer', {'data-symbol': self.ticker})\n",
    "            price = float(data['value'])\n",
    "            self.price = price\n",
    "\n",
    "        except:\n",
    "            print(f'Price not available for {self.ticker}')\n",
    "            self.price = 0.0\n",
    "            \n",
    "    def get_historical(self):\n",
    "        # grab price history saved as dataframe\n",
    "        stock = yf.Ticker(self.ticker)\n",
    "        history = stock.history(start = '2011-01-01', end='2023-05-31')\n",
    "        self.pricehistory = history\n",
    "        \n",
    "        \n",
    "    def add_technical_indicators(self):\n",
    "        # get historical stock prices\n",
    "        prices = self.pricehistory\n",
    "        if len(prices) < 20:\n",
    "            return\n",
    "        \n",
    "        # calculate 20-day moving average\n",
    "        prices['MA20'] = prices['Close'].rolling(window=20).mean()\n",
    "        \n",
    "        # calculate 50-day moving average\n",
    "        prices['MA50'] = prices['Close'].rolling(window=50).mean()\n",
    "        \n",
    "        # calculate relative strength index (RSI), window = 14 days\n",
    "        delta = prices['Close'].diff()\n",
    "        gain = delta.where(delta > 0, 0)\n",
    "        loss = -delta.where(delta < 0, 0)\n",
    "        avg_gain = gain.rolling(window=14).mean()\n",
    "        avg_loss = loss.rolling(window=14).mean()\n",
    "        rs = avg_gain / avg_loss\n",
    "        prices['RSI'] = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        # calculate moving average convergence divergence (MACD)\n",
    "        exp1 = prices['Close'].ewm(span=12, adjust=False).mean()\n",
    "        exp2 = prices['Close'].ewm(span=26, adjust=False).mean()\n",
    "        macd = exp1 - exp2\n",
    "        signal = macd.ewm(span=9, adjust=False).mean()\n",
    "        prices['MACD'] = macd - signal\n",
    "        \n",
    "        # calculate Bollinger Bands, window = 20 days\n",
    "        prices['20MA'] = prices['Close'].rolling(window=20).mean()\n",
    "        prices['20STD'] = prices['Close'].rolling(window=20).std()\n",
    "        prices['UpperBand'] = prices['20MA'] + (prices['20STD'] * 2)\n",
    "        prices['LowerBand'] = prices['20MA'] - (prices['20STD'] * 2)\n",
    "\n",
    "        # Features for deep learning model, train_set exclude last 10 days technical indicator\n",
    "        train_data_aux = prices[['Close', 'MA20', 'MA50', 'RSI', 'MACD', 'UpperBand', 'LowerBand']].dropna()\n",
    "        self.technical_indicators = train_data_aux.iloc[:-10, :].drop('Close', axis=1) \n",
    "\n",
    "        # Set label as profit/loss of 10 day future price from actual price, use last 10 days to label\n",
    "        labels_aux = (train_data_aux['Close'].shift(-10) > train_data_aux['Close']).astype(int)\n",
    "        self.labels =  labels_aux[:-10]\n",
    "\n",
    "        # Today features for prediction\n",
    "        self.today_technical_indicators = prices[['MA20', 'MA50', 'RSI', 'MACD', 'UpperBand', 'LowerBand']].iloc[-1,:] \n",
    "\n",
    "        prices = prices.reset_index()\n",
    "        # store technical indicators in stock data dictionary\n",
    "        self.data.update(prices[['Date', 'MA20', 'MA50', 'RSI', 'MACD', 'UpperBand', 'LowerBand']].to_dict('list'))   \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stocks Screener Class, store stocks in stock class as a list\n",
    "class StockScreener:\n",
    "    def __init__(self, stocks):\n",
    "        self.stocks = stocks\n",
    "        self.scaler = StandardScaler()\n",
    "        self.models = {}\n",
    "\n",
    "    # Add data to stocks, can be used for filter\n",
    "    def add_data(self):\n",
    "        i = 1\n",
    "        for stock in self.stocks:\n",
    "            stock.scrape_data()\n",
    "            stock.get_stock_price()\n",
    "            print(i)\n",
    "            i += 1\n",
    "\n",
    "    # Select stocks list that pass all filters\n",
    "    def apply_filters(self, filters):\n",
    "        filtered_stocks = []\n",
    "        for stock in self.stocks:\n",
    "            passed_all_filters = True\n",
    "            for filter_func in filters:\n",
    "                if not filter_func(stock):\n",
    "                    passed_all_filters = False\n",
    "                    break\n",
    "            if passed_all_filters:\n",
    "                filtered_stocks.append(stock)\n",
    "        return filtered_stocks\n",
    "    \n",
    "    #Add deep learning related data to selected stocks (passed all filter or specified), pass a list of stock class\n",
    "    def prepare_new_stocks(self, new_stocks):\n",
    "        for stock in new_stocks:\n",
    "            stock.get_historical()\n",
    "            stock.add_technical_indicators()\n",
    "            \n",
    "    # Train deep learning models on selected stocks, supervised learning, use technical_indicators to predict >0 profit\n",
    "    def train_models(self, new_stocks):\n",
    "        for stock in new_stocks:\n",
    "            if stock.technical_indicators is not None:\n",
    "                train_data = stock.technical_indicators\n",
    "                train_labels = stock.labels\n",
    "\n",
    "                # Normalize the data\n",
    "                train_data = self.scaler.fit_transform(train_data)\n",
    "                train_labels = np.array(train_labels)\n",
    "\n",
    "                # Create and train model, add stock's model to screener models dictionary\n",
    "                model = create_model(train_data)\n",
    "                model.fit(train_data, train_labels, epochs=10)\n",
    "                self.models[stock.ticker] = model\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    # Predict whether new stocks will pass filters\n",
    "    def predict_stocks(self, new_stocks):\n",
    "        # Add technical indicators to new stocks, generate models\n",
    "        self.prepare_new_stocks(new_stocks)\n",
    "        self.train_models(new_stocks)\n",
    "        \n",
    "        # Make predictions for each stock using its corresponding model\n",
    "        predicted_stocks = []\n",
    "        for stock in new_stocks:\n",
    "            if stock.ticker in self.models:\n",
    "                #grab stock's model\n",
    "                model = self.models[stock.ticker]\n",
    "                # Reshape as there is only one sample,use today's technical indicator to predict future 10 days profit\n",
    "                new_features_aux = np.array(stock.today_technical_indicators).reshape(1, -1)\n",
    "                new_stock_data = self.scaler.fit_transform(new_features_aux)\n",
    "                prediction = model.predict(new_stock_data)\n",
    "                stock.prediction = prediction\n",
    "                if prediction > 0.6: #0.5\n",
    "                    predicted_stocks.append(stock)\n",
    "\n",
    "        return predicted_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Dense model \n",
    "def create_model(train_data):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(64, input_shape=(train_data.shape[1],), activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sector(stock, sector):\n",
    "    return stock.sector == sector\n",
    "\n",
    "def filter_price(stock, min_price, max_price):\n",
    "    return min_price <= stock.price <= max_price\n",
    "\n",
    "def filter_technical_indicator(stock, indicator_name, operator, value):\n",
    "    if indicator_name not in stock.today_technical_indicators:\n",
    "        return False\n",
    "\n",
    "    # Obtain the value of the technical indicator\n",
    "    indicator_value = stock.today_technical_indicators[indicator_name]\n",
    "    \n",
    "    # Check if the value is 'price':\n",
    "    if value == 'price':\n",
    "        value = float(stock.price)\n",
    "    else:\n",
    "        value = float(value)\n",
    "    \n",
    "    # Compare according to operator\n",
    "    if operator == '>':\n",
    "        return float(indicator_value) > value\n",
    "    elif operator == '>=':\n",
    "        return float(indicator_value) >= value\n",
    "    elif operator == '<':\n",
    "        return float(indicator_value) < value\n",
    "    elif operator == '<=':\n",
    "        return float(indicator_value) <= value\n",
    "    elif operator == '==':\n",
    "        return float(indicator_value) == value\n",
    "    else:\n",
    "        return False\n",
    "       \n",
    "def filter_metric(stock, metric, operator, value):\n",
    "    if metric not in stock.data:\n",
    "        print('hola')\n",
    "        return False\n",
    "\n",
    "    # Convert value to same units as metric, if necessary\n",
    "    if 'B' in stock.data[metric]:\n",
    "        stock.data[metric] = stock.data[metric].replace('B', '')\n",
    "        value = float(value) / 1e9\n",
    "    elif 'M' in stock.data[metric]:\n",
    "        stock.data[metric] = stock.data[metric].replace('M', '')\n",
    "        value = float(value) / 1e6\n",
    "    elif '%' in stock.data[metric]:\n",
    "        stock.data[metric] = stock.data[metric].replace('%', '')\n",
    "        value = float(value)\n",
    "    else:\n",
    "        value = float(value)\n",
    "\n",
    "    # Check condition according to operator\n",
    "    if operator == '>':\n",
    "        return float(stock.data[metric]) > value\n",
    "    elif operator == '>=':\n",
    "        return float(stock.data[metric]) >= value\n",
    "    elif operator == '<':\n",
    "        return float(stock.data[metric]) < value\n",
    "    elif operator == '<=':\n",
    "        return float(stock.data[metric]) <= value\n",
    "    elif operator == '==':\n",
    "        return float(stock.data[metric]) == value\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dict of stock to stock class\n",
    "def stockuniverse(stocklist):\n",
    "    stockuniverse = [Stock(stock['ticker'], stock['sector']) for stock in stocklist]\n",
    "    return stockuniverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sp500 ticker and sector\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "rows = table.find_all('tr')[1:]  # skip the header row\n",
    "\n",
    "sp500 = []\n",
    "\n",
    "for row in rows:\n",
    "    cells = row.find_all('td')\n",
    "    ticker = cells[0].text.strip()\n",
    "    company = cells[1].text.strip()\n",
    "    sector = cells[3].text.strip()\n",
    "    sp500.append({'ticker': ticker, 'company': company, 'sector': sector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Get sp500 tickers and sectors, use first 10 stocks\n",
    "sp500_stocks = stockuniverse(sp500[:20])\n",
    "# Screener\n",
    "screener = StockScreener(sp500_stocks)\n",
    "# Add Data\n",
    "screener.add_data()\n",
    "\n",
    "# Run screener for all sp500 tickers\n",
    "filters = [#lambda stock: filter_sector(stock, 'Industrial Conglomerates'),\n",
    "           #lambda stock: filter_price(stock, 60, 200),\n",
    "           #lambda stock: filter_metric(stock, 'profit_margin', '>', 15),\n",
    "           #lambda stock: filter_technical_indicator(stock, 'UpperBand', '>', 'price'),\n",
    "           #lambda stock: filter_technical_indicator(stock, 'LowerBand', '<', 'price'),\n",
    "]\n",
    "\n",
    "# Apply Filters\n",
    "filtered_stocks = screener.apply_filters(filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "96/96 [==============================] - 1s 1ms/step - loss: 0.6811 - accuracy: 0.5661\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.5664\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.5694\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6735 - accuracy: 0.5779\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.5743\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6713 - accuracy: 0.5736\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6699 - accuracy: 0.5867\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6690 - accuracy: 0.5877\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6668 - accuracy: 0.5929\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6658 - accuracy: 0.5955\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 1s 1ms/step - loss: 0.6772 - accuracy: 0.5870\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6638 - accuracy: 0.6151\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 0.6131\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6553 - accuracy: 0.6154\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6180\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6527 - accuracy: 0.6200\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6183\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6466 - accuracy: 0.6239\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6460 - accuracy: 0.6288\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6448 - accuracy: 0.6301\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 1s 1ms/step - loss: 0.6748 - accuracy: 0.5837\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6665 - accuracy: 0.6020\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6640 - accuracy: 0.6014\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6637 - accuracy: 0.6024\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6613 - accuracy: 0.5984\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6582 - accuracy: 0.6115\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6577 - accuracy: 0.6059\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6554 - accuracy: 0.6095\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6141\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.6177\n",
      "Epoch 1/10\n",
      "81/81 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5666\n",
      "Epoch 2/10\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6802 - accuracy: 0.5736\n",
      "Epoch 3/10\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6780 - accuracy: 0.5791\n",
      "Epoch 4/10\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.5767\n",
      "Epoch 5/10\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6754 - accuracy: 0.5822\n",
      "Epoch 6/10\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6733 - accuracy: 0.5779\n",
      "Epoch 7/10\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6732 - accuracy: 0.5791\n",
      "Epoch 8/10\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.5818\n",
      "Epoch 9/10\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6696 - accuracy: 0.5845\n",
      "Epoch 10/10\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.6679 - accuracy: 0.5818\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 1s 2ms/step - loss: 0.6715 - accuracy: 0.6105\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6634 - accuracy: 0.6174\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.6112\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.6170\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6587 - accuracy: 0.6164\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6557 - accuracy: 0.6187\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.6187\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.6180\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6174\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6200\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5544\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.5733\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.5890\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6738 - accuracy: 0.5850\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.5929\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6696 - accuracy: 0.6030\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.5893\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6681 - accuracy: 0.6030\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6655 - accuracy: 0.5994\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6669 - accuracy: 0.5997\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 1s 1ms/step - loss: 0.6894 - accuracy: 0.5521\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6751 - accuracy: 0.5841\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6728 - accuracy: 0.5867\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.5932\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6694 - accuracy: 0.5994\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6678 - accuracy: 0.6020\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.6010\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6671 - accuracy: 0.5952\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.6072\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6636 - accuracy: 0.6066\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 1s 1ms/step - loss: 0.6721 - accuracy: 0.6115\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6655 - accuracy: 0.6183\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6638 - accuracy: 0.6203\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6620 - accuracy: 0.6151\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6614 - accuracy: 0.6170\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6631 - accuracy: 0.6197\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6216\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6580 - accuracy: 0.6242\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6568 - accuracy: 0.6223\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6582 - accuracy: 0.6216\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 1s 1ms/step - loss: 0.6704 - accuracy: 0.6063\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6620 - accuracy: 0.6161\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.6187\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6187\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6546 - accuracy: 0.6170\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6531 - accuracy: 0.6216\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6203\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6183\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6252\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6213\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 1s 1ms/step - loss: 0.6902 - accuracy: 0.5433\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.5648\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5677\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6775 - accuracy: 0.5704\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6761 - accuracy: 0.5717\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6740 - accuracy: 0.5788\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6728 - accuracy: 0.5808\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6729 - accuracy: 0.5739\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.5864\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6696 - accuracy: 0.5880\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 1s 1ms/step - loss: 0.6922 - accuracy: 0.5318\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5615\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6790 - accuracy: 0.5674\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6737 - accuracy: 0.5762\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6713 - accuracy: 0.5713\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6708 - accuracy: 0.5795\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6672 - accuracy: 0.5867\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6667 - accuracy: 0.5870\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6646 - accuracy: 0.5867\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6626 - accuracy: 0.5913\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 1s 1ms/step - loss: 0.6906 - accuracy: 0.5563\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6790 - accuracy: 0.5847\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6754 - accuracy: 0.5867\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6731 - accuracy: 0.5906\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6715 - accuracy: 0.5955\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6696 - accuracy: 0.5971\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6679 - accuracy: 0.5958\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6669 - accuracy: 0.5997\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6679 - accuracy: 0.5997\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6658 - accuracy: 0.6027\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5739\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6796 - accuracy: 0.5762\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.5798\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.5788\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6762 - accuracy: 0.5847\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6751 - accuracy: 0.5877\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6739 - accuracy: 0.5834\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.5824\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6742 - accuracy: 0.5864\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6735 - accuracy: 0.5841\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 1s 1ms/step - loss: 0.6831 - accuracy: 0.5596\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6771 - accuracy: 0.5802\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6750 - accuracy: 0.5726\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6731 - accuracy: 0.5788\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6719 - accuracy: 0.5798\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6703 - accuracy: 0.5808\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6692 - accuracy: 0.5769\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6676 - accuracy: 0.5824\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6665 - accuracy: 0.5877\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6662 - accuracy: 0.5785\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 1s 1ms/step - loss: 0.6938 - accuracy: 0.5341\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6822 - accuracy: 0.5655\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.5739\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.5766\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6745 - accuracy: 0.5929\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6745 - accuracy: 0.5893\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6724 - accuracy: 0.5831\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6716 - accuracy: 0.5896\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6689 - accuracy: 0.5919\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6695 - accuracy: 0.5844\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5508\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6749 - accuracy: 0.5909\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6726 - accuracy: 0.5899\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.6033\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6713 - accuracy: 0.5873\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6694 - accuracy: 0.5968\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6676 - accuracy: 0.6004\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6674 - accuracy: 0.5997\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6673 - accuracy: 0.5991\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6663 - accuracy: 0.5984\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 1s 1ms/step - loss: 0.6893 - accuracy: 0.5403\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.5455\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6845 - accuracy: 0.5547\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5563\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5635\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.5704\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.5720\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6785 - accuracy: 0.5697\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6787 - accuracy: 0.5655\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6766 - accuracy: 0.5746\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 1s 1ms/step - loss: 0.6835 - accuracy: 0.5664\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6720 - accuracy: 0.5939\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6698 - accuracy: 0.5958\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6676 - accuracy: 0.6010\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6639 - accuracy: 0.6014\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6632 - accuracy: 0.6043\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6605 - accuracy: 0.6027\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.6121\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.6099\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6548 - accuracy: 0.6141\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 1s 1ms/step - loss: 0.6792 - accuracy: 0.5834\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6708 - accuracy: 0.5984\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6668 - accuracy: 0.5991\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.6040\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6577 - accuracy: 0.6141\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.6092\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6190\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6219\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6443 - accuracy: 0.6291\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.6425 - accuracy: 0.6275\n",
      "Epoch 1/10\n",
      "74/74 [==============================] - 1s 1ms/step - loss: 0.6866 - accuracy: 0.5656\n",
      "Epoch 2/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5690\n",
      "Epoch 3/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.6777 - accuracy: 0.5789\n",
      "Epoch 4/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.6758 - accuracy: 0.5806\n",
      "Epoch 5/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.6733 - accuracy: 0.5819\n",
      "Epoch 6/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.6718 - accuracy: 0.5814\n",
      "Epoch 7/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.6697 - accuracy: 0.5909\n",
      "Epoch 8/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.6666 - accuracy: 0.5879\n",
      "Epoch 9/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.6675 - accuracy: 0.5904\n",
      "Epoch 10/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.6629 - accuracy: 0.5866\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8351ac0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f835205a040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AOS',\n",
       " 'ABT',\n",
       " 'ACN',\n",
       " 'ATVI',\n",
       " 'ADBE',\n",
       " 'ADP',\n",
       " 'AES',\n",
       " 'A',\n",
       " 'APD',\n",
       " 'ALK',\n",
       " 'ALGN',\n",
       " 'ALLE']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions, grab/analyze past historical price for filtered_stocks\n",
    "predicted_stocks = screener.predict_stocks(filtered_stocks)\n",
    "\n",
    "final_list = []\n",
    "for predicted_stock in predicted_stocks:\n",
    "    final_list.append(predicted_stock.ticker)\n",
    "final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original list: sp500 -> sp500_stocks -> screener.stocks (store stock class as a list)\n",
    "#Individual stock: screener.stocks[0], screener.stocks[1]\n",
    "#Individual stock original stats: screener.stocks[0].ticker, screener.stocks[0].sector\n",
    "#Individual stock later added for filter: screener.stocks[0].data, screener.stocks[0].price, screener.stocks[0].metrics\n",
    "#screener.stocks[0].technical_indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#improvements: use Eikon or other source to grab stocks' info quickly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
